{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tenemos dos modelos, uno con 3 parámetros y otro con 5 parámetros.\n",
    "# Definimos las funciones model1_run y model2_run\n",
    "\n",
    "def model1_run(d, a, rho, sigmaConf, theta):\n",
    "    # Aquí iría tu lógica específica para model1 con 3 parámetros\n",
    "    pass\n",
    "\n",
    "def model2_run(d, a, rho, sigmaConf, theta, alpha, beta):\n",
    "    # Aquí iría tu lógica específica para model2 con 5 parámetros\n",
    "    pass\n",
    "\n",
    "# Función negativa de log-likelihood para model1 (con 3 parámetros)\n",
    "def negative_log_likelihood_model1(params, data):\n",
    "    rho, sigmaConf, theta = params\n",
    "    all_secondOrder_mean_cor = []\n",
    "\n",
    "    for n_p in data['Subj_idx'].unique():\n",
    "        df_vp_participant = data[data['Subj_idx'] == n_p]\n",
    "        d = df_vp_participant['Stimulus_transformed'].values\n",
    "        a = df_vp_participant['Response_transformed'].values\n",
    "        secondOrder_mean_cor = model1_run(d, a, rho, sigmaConf, theta)\n",
    "        all_secondOrder_mean_cor.extend(secondOrder_mean_cor)\n",
    "\n",
    "    all_secondOrder_mean_cor = np.array(all_secondOrder_mean_cor)\n",
    "    conf_data = data.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)['Confidence_0to1'].values\n",
    "\n",
    "    epsilon = 1e-10\n",
    "    all_secondOrder_mean_cor = np.clip(all_secondOrder_mean_cor, epsilon, 1 - epsilon)\n",
    "    log_likelihood = np.sum(norm.logpdf(conf_data, all_secondOrder_mean_cor))\n",
    "\n",
    "    return -log_likelihood\n",
    "\n",
    "# Función negativa de log-likelihood para model2 (con 5 parámetros)\n",
    "def negative_log_likelihood_model2(params, data):\n",
    "    rho, sigmaConf, theta, alpha, beta = params\n",
    "    all_secondOrder_mean_cor = []\n",
    "\n",
    "    for n_p in data['Subj_idx'].unique():\n",
    "        df_vp_participant = data[data['Subj_idx'] == n_p]\n",
    "        d = df_vp_participant['Stimulus_transformed'].values\n",
    "        a = df_vp_participant['Response_transformed'].values\n",
    "        secondOrder_mean_cor = model2_run(d, a, rho, sigmaConf, theta, alpha, beta)\n",
    "        all_secondOrder_mean_cor.extend(secondOrder_mean_cor)\n",
    "\n",
    "    all_secondOrder_mean_cor = np.array(all_secondOrder_mean_cor)\n",
    "    conf_data = data.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)['Confidence_0to1'].values\n",
    "\n",
    "    epsilon = 1e-10\n",
    "    all_secondOrder_mean_cor = np.clip(all_secondOrder_mean_cor, epsilon, 1 - epsilon)\n",
    "    log_likelihood = np.sum(norm.logpdf(conf_data, all_secondOrder_mean_cor))\n",
    "\n",
    "    return -log_likelihood\n",
    "\n",
    "# Definimos una función para calcular AIC y BIC\n",
    "def calculate_aic_bic(log_likelihood, num_params, num_observations):\n",
    "    aic = 2 * num_params - 2 * log_likelihood\n",
    "    bic = np.log(num_observations) * num_params - 2 * log_likelihood\n",
    "    return aic, bic\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('data_Mazancieux_2018.csv')\n",
    "suj = [1,2,3]\n",
    "df_vp = df[(df['Task'] == 'VP') & (df['Subj_idx'].isin(suj))].copy()\n",
    "df_vp.loc[:, 'Stimulus_transformed'] = df_vp['Stimulus'].replace({1: -1, 2: 1})\n",
    "df_vp.loc[:, 'Response_transformed'] = df_vp['Response'].replace({1: 0, 2: 1})\n",
    "df_vp['Confidence_0to1'] = df_vp['Confidence'] / 10\n",
    "\n",
    "# Número de observaciones\n",
    "num_observations = len(df_vp)\n",
    "\n",
    "# Optimización de los parámetros para model1\n",
    "initial_guess_model1 = [0.2, 0.5, 0.8]  # Supongamos que estos son los parámetros iniciales para model1\n",
    "bounds_model1 = [(0, 1), (0.1, 2), (0.1, 0.9)]\n",
    "result_model1 = minimize(negative_log_likelihood_model1, initial_guess_model1, args=(df_vp,), bounds=bounds_model1, method='Powell')\n",
    "params_model1 = result_model1.x\n",
    "log_likelihood_model1 = -result_model1.fun\n",
    "\n",
    "# Optimización de los parámetros para model2\n",
    "initial_guess_model2 = [0.2, 0.5, 0.8, 0.4, 0.6]  # Supongamos que estos son los parámetros iniciales para model2\n",
    "bounds_model2 = [(0, 1), (0.1, 2), (0.1, 0.9), (0, 1), (0, 1)]\n",
    "result_model2 = minimize(negative_log_likelihood_model2, initial_guess_model2, args=(df_vp,), bounds=bounds_model2, method='Powell')\n",
    "params_model2 = result_model2.x\n",
    "log_likelihood_model2 = -result_model2.fun\n",
    "\n",
    "# Calcular AIC y BIC para cada modelo\n",
    "num_params_model1 = len(params_model1)\n",
    "num_params_model2 = len(params_model2)\n",
    "\n",
    "aic_model1, bic_model1 = calculate_aic_bic(log_likelihood_model1, num_params_model1, num_observations)\n",
    "aic_model2, bic_model2 = calculate_aic_bic(log_likelihood_model2, num_params_model2, num_observations)\n",
    "\n",
    "# Comparar los resultados\n",
    "results = [\n",
    "    {'model': 'model1', 'log_likelihood': log_likelihood_model1, 'aic': aic_model1, 'bic': bic_model1},\n",
    "    {'model': 'model2', 'log_likelihood': log_likelihood_model2, 'aic': aic_model2, 'bic': bic_model2}\n",
    "]\n",
    "\n",
    "# Convertir resultados a DataFrame para mejor visualización\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
