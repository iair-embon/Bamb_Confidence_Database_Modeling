{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm,multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FLEMING'S FUNCTION MODIFIED\n",
    "def compute_meta_conf_serialdependence(xp, a, sigma_act, sigma_conf, rho):\n",
    "    \n",
    "    dhat = np.array([-1, 1])\n",
    "    mu_x_xp_dhat = np.zeros((2, len(xp)))\n",
    "    var_x_xp_dhat = np.zeros(len(xp))\n",
    "    rho_vec = np.full(len(xp), rho)\n",
    "    sigA_vec = np.full(len(xp), sigma_act)\n",
    "    sigP_vec = np.full(len(xp), sigma_conf)\n",
    "    \n",
    "    Tol = 10e-4\n",
    "\n",
    "    for dhati in range(2):\n",
    "        dhat_vec = np.full(len(xp), dhat[dhati])\n",
    "        \n",
    "        mu_x_xp_dhat[dhati, :] = dhat_vec + (sigA_vec / sigP_vec) * rho_vec * (xp - dhat_vec)\n",
    "        var_x_xp_dhat = (1 - rho_vec**2) * sigA_vec**2\n",
    "        \n",
    "        if a == 1:\n",
    "            p_a_dhat_xp = 1 - norm.cdf(0, mu_x_xp_dhat[dhati, :], np.sqrt(var_x_xp_dhat))\n",
    "        else:\n",
    "            p_a_dhat_xp = norm.cdf(0, mu_x_xp_dhat[dhati, :], np.sqrt(var_x_xp_dhat))\n",
    "        \n",
    "        lik_d = norm.pdf(xp, dhat_vec, sigP_vec)\n",
    "        \n",
    "        if dhati == 0:\n",
    "            p_a_dhat_xp_full = p_a_dhat_xp\n",
    "            lik_d_full = lik_d\n",
    "        else:\n",
    "            p_a_dhat_xp_full = np.vstack((p_a_dhat_xp_full, p_a_dhat_xp))\n",
    "            lik_d_full = np.vstack((lik_d_full, lik_d))\n",
    "    \n",
    "    # manage probability\n",
    "    p_a_dhat_xp_full = np.clip(p_a_dhat_xp_full, Tol, None)\n",
    "    lik_d_full = np.clip(lik_d_full, Tol, None)\n",
    "    \n",
    "    lik_d_full = lik_d_full / np.sum(lik_d_full, axis=0, keepdims=True)\n",
    "    p_dhat_xp_a = p_a_dhat_xp_full * lik_d_full\n",
    "    p_dhat_xp_a = p_dhat_xp_a / np.sum(p_dhat_xp_a, axis=0, keepdims=True)\n",
    "    \n",
    "    # Conf = p(a=d)\n",
    "    if a == 1:\n",
    "        conf = p_dhat_xp_a[1, :]\n",
    "    else:\n",
    "        conf = p_dhat_xp_a[0, :]\n",
    "    \n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model  log_likelihood           aic           bic\n",
      "0  model1    -7013.658000  14033.316000  14053.978130\n",
      "1  model2    -6944.571776  13899.143553  13933.580435\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tenemos dos modelos, uno con 3 parámetros y otro con 5 parámetros.\n",
    "# Definimos las funciones model1_run y model2_run\n",
    "\n",
    "def model1_run(d, a, rho, sigmaConf, theta):\n",
    "    # Aquí iría tu lógica específica para model1 con 3 parámetros\n",
    "    sigmaAct = 1\n",
    "    bigSigma = np.array([[sigmaAct**2, rho * sigmaAct * sigmaConf], [rho * sigmaAct * sigmaConf, sigmaConf**2]])\n",
    "\n",
    "    N = len(d)\n",
    "    xa = np.empty(N)\n",
    "    xp = np.empty(N)\n",
    "    secondOrder_mean_cor = np.empty(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        current_theta = theta\n",
    "        r = multivariate_normal.rvs(mean=[d[i] * current_theta, d[i] * current_theta], cov=bigSigma)\n",
    "        \n",
    "        xa[i] = r[0]\n",
    "        xp[i] = r[1]\n",
    "        \n",
    "        flip_a = a[i]\n",
    "\n",
    "        secondOrder_mean_cor[i] = compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "\n",
    "    secondOrder_mean_cor_adj = secondOrder_mean_cor[1:]\n",
    "\n",
    "    return secondOrder_mean_cor_adj\n",
    "\n",
    "def model2_run(d, a, rho, sigmaConf, theta, alpha, beta):\n",
    "    # Aquí iría tu lógica específica para model2 con 5 parámetros\n",
    "    sigmaAct = 1\n",
    "    bigSigma = np.array([[sigmaAct**2, rho * sigmaAct * sigmaConf], [rho * sigmaAct * sigmaConf, sigmaConf**2]])\n",
    "\n",
    "    N = len(d)\n",
    "    xa = np.empty(N)\n",
    "    xp = np.empty(N)\n",
    "    secondOrder_mean_cor_serialDependence =  np.full( N, 111.0)\n",
    "    first_trial = True \n",
    "\n",
    "    for i in range(N):\n",
    "        current_theta = theta\n",
    "        r = multivariate_normal.rvs(mean=[d[i] * current_theta, d[i] * current_theta], cov=bigSigma)\n",
    "        \n",
    "        xa[i] = r[0]\n",
    "        xp[i] = r[1]\n",
    "        \n",
    "        flip_a = a[i]\n",
    "        \n",
    "        if first_trial == False:\n",
    "            p_serial_dependence = np.random.beta(alpha, beta, 1)[0]\n",
    "            secondOrder_mean_cor_serialDependence[i] = (\n",
    "                p_serial_dependence * secondOrder_mean_cor_serialDependence[i-1] + \n",
    "                (1-p_serial_dependence) * compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "            )\n",
    "        else:\n",
    "            secondOrder_mean_cor_serialDependence[i] = compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "    \n",
    "        first_trial = False\n",
    "\n",
    "    # drop first value\n",
    "    secondOrder_mean_cor_serialDependence_adj = secondOrder_mean_cor_serialDependence[1:]\n",
    "\n",
    "    return secondOrder_mean_cor_serialDependence_adj\n",
    "\n",
    "\n",
    "# Función negativa de log-likelihood para model1 (con 3 parámetros)\n",
    "def negative_log_likelihood_model1(params, data):\n",
    "    rho, sigmaConf, theta = params\n",
    "    all_secondOrder_mean_cor = []\n",
    "\n",
    "    for n_p in data['Subj_idx'].unique():\n",
    "        df_vp_participant = data[data['Subj_idx'] == n_p]\n",
    "        d = df_vp_participant['Stimulus_transformed'].values\n",
    "        a = df_vp_participant['Response_transformed'].values\n",
    "        secondOrder_mean_cor = model1_run(d, a, rho, sigmaConf, theta)\n",
    "        all_secondOrder_mean_cor.extend(secondOrder_mean_cor)\n",
    "\n",
    "    all_secondOrder_mean_cor = np.array(all_secondOrder_mean_cor)\n",
    "    grouped = df_vp.groupby('Subj_idx')\n",
    "    df_vp_cleaned = pd.concat([group.iloc[1:] for _, group in grouped]).reset_index(drop=True)\n",
    "    conf_data = df_vp_cleaned['Confidence_0to1'].values\n",
    "\n",
    "    epsilon = 1e-10\n",
    "    all_secondOrder_mean_cor = np.clip(all_secondOrder_mean_cor, epsilon, 1 - epsilon)\n",
    "    log_likelihood = np.sum(norm.logpdf(conf_data, all_secondOrder_mean_cor))\n",
    "\n",
    "    return -log_likelihood\n",
    "\n",
    "# Función negativa de log-likelihood para model2 (con 5 parámetros)\n",
    "def negative_log_likelihood_model2(params, data):\n",
    "    rho, sigmaConf, theta, alpha, beta = params\n",
    "    all_secondOrder_mean_cor = []\n",
    "\n",
    "    for n_p in data['Subj_idx'].unique():\n",
    "        df_vp_participant = data[data['Subj_idx'] == n_p]\n",
    "        d = df_vp_participant['Stimulus_transformed'].values\n",
    "        a = df_vp_participant['Response_transformed'].values\n",
    "        secondOrder_mean_cor = model2_run(d, a, rho, sigmaConf, theta, alpha, beta)\n",
    "        all_secondOrder_mean_cor.extend(secondOrder_mean_cor)\n",
    "\n",
    "    all_secondOrder_mean_cor = np.array(all_secondOrder_mean_cor)\n",
    "    grouped = df_vp.groupby('Subj_idx')\n",
    "    df_vp_cleaned = pd.concat([group.iloc[1:] for _, group in grouped]).reset_index(drop=True)\n",
    "    conf_data = df_vp_cleaned['Confidence_0to1'].values\n",
    "\n",
    "    epsilon = 1e-10\n",
    "    all_secondOrder_mean_cor = np.clip(all_secondOrder_mean_cor, epsilon, 1 - epsilon)\n",
    "    log_likelihood = np.sum(norm.logpdf(conf_data, all_secondOrder_mean_cor))\n",
    "\n",
    "    return -log_likelihood\n",
    "\n",
    "# Definimos una función para calcular AIC y BIC\n",
    "def calculate_aic_bic(log_likelihood, num_params, num_observations):\n",
    "    aic = 2 * num_params - 2 * log_likelihood\n",
    "    bic = np.log(num_observations) * num_params - 2 * log_likelihood\n",
    "    return aic, bic\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('data_Mazancieux_2018.csv')\n",
    "#suj = [1,2,3]\n",
    "#df_vp = df[(df['Task'] == 'VP') & (df['Subj_idx'].isin(suj))].copy()\n",
    "df_vp = df[df['Task'] == 'EM'].copy()\n",
    "df_vp.loc[:, 'Stimulus_transformed'] = df_vp['Stimulus'].replace({1: -1, 2: 1})\n",
    "df_vp.loc[:, 'Response_transformed'] = df_vp['Response'].replace({1: 0, 2: 1})\n",
    "df_vp['Confidence_0to1'] = df_vp['Confidence'] / 10\n",
    "\n",
    "# Número de observaciones\n",
    "num_observations = len(df_vp)\n",
    "\n",
    "# Optimización de los parámetros para model1\n",
    "initial_guess_model1 = [0.5, 1.0, 0.5]  # Supongamos que estos son los parámetros iniciales para model1\n",
    "bounds_model1 = [(0.0001, 0.9999), (0.1, 2), (0.1, 0.9)]\n",
    "result_model1 = minimize(negative_log_likelihood_model1, initial_guess_model1, args=(df_vp,), bounds=bounds_model1, method='Powell')\n",
    "params_model1 = result_model1.x\n",
    "log_likelihood_model1 = -result_model1.fun\n",
    "\n",
    "# Optimización de los parámetros para model2\n",
    "initial_guess_model2 = [0.5, 1.0, 0.5, 3, 7]  # Supongamos que estos son los parámetros iniciales para model2\n",
    "bounds_model2 = [(0.0001, 0.9999), (0.1, 2), (0.1, 0.9), (1, 20), (1, 20)]\n",
    "result_model2 = minimize(negative_log_likelihood_model2, initial_guess_model2, args=(df_vp,), bounds=bounds_model2, method='Powell')\n",
    "params_model2 = result_model2.x\n",
    "log_likelihood_model2 = -result_model2.fun\n",
    "\n",
    "# Calcular AIC y BIC para cada modelo\n",
    "num_params_model1 = len(params_model1)\n",
    "num_params_model2 = len(params_model2)\n",
    "\n",
    "aic_model1, bic_model1 = calculate_aic_bic(log_likelihood_model1, num_params_model1, num_observations)\n",
    "aic_model2, bic_model2 = calculate_aic_bic(log_likelihood_model2, num_params_model2, num_observations)\n",
    "\n",
    "# Comparar los resultados\n",
    "results = [\n",
    "    {'model': 'model1', 'log_likelihood': log_likelihood_model1, 'aic': aic_model1, 'bic': bic_model1},\n",
    "    {'model': 'model2', 'log_likelihood': log_likelihood_model2, 'aic': aic_model2, 'bic': bic_model2}\n",
    "]\n",
    "\n",
    "# Convertir resultados a DataFrame para mejor visualización\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
