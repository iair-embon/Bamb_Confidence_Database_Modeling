{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FLEMING'S FUNCTION MODIFIED\n",
    "def compute_meta_conf_serialdependence(xp, a, sigma_act, sigma_conf, rho):\n",
    "    \n",
    "    dhat = np.array([-1, 1])\n",
    "    mu_x_xp_dhat = np.zeros((2, len(xp)))\n",
    "    var_x_xp_dhat = np.zeros(len(xp))\n",
    "    rho_vec = np.full(len(xp), rho)\n",
    "    sigA_vec = np.full(len(xp), sigma_act)\n",
    "    sigP_vec = np.full(len(xp), sigma_conf)\n",
    "    \n",
    "    Tol = 10e-4\n",
    "\n",
    "    for dhati in range(2):\n",
    "        dhat_vec = np.full(len(xp), dhat[dhati])\n",
    "        \n",
    "        mu_x_xp_dhat[dhati, :] = dhat_vec + (sigA_vec / sigP_vec) * rho_vec * (xp - dhat_vec)\n",
    "        var_x_xp_dhat = (1 - rho_vec**2) * sigA_vec**2\n",
    "        \n",
    "        if a == 1:\n",
    "            p_a_dhat_xp = 1 - norm.cdf(0, mu_x_xp_dhat[dhati, :], np.sqrt(var_x_xp_dhat))\n",
    "        else:\n",
    "            p_a_dhat_xp = norm.cdf(0, mu_x_xp_dhat[dhati, :], np.sqrt(var_x_xp_dhat))\n",
    "        \n",
    "        lik_d = norm.pdf(xp, dhat_vec, sigP_vec)\n",
    "        \n",
    "        if dhati == 0:\n",
    "            p_a_dhat_xp_full = p_a_dhat_xp\n",
    "            lik_d_full = lik_d\n",
    "        else:\n",
    "            p_a_dhat_xp_full = np.vstack((p_a_dhat_xp_full, p_a_dhat_xp))\n",
    "            lik_d_full = np.vstack((lik_d_full, lik_d))\n",
    "    \n",
    "    # manage probability\n",
    "    p_a_dhat_xp_full = np.clip(p_a_dhat_xp_full, Tol, None)\n",
    "    lik_d_full = np.clip(lik_d_full, Tol, None)\n",
    "    \n",
    "    lik_d_full = lik_d_full / np.sum(lik_d_full, axis=0, keepdims=True)\n",
    "    p_dhat_xp_a = p_a_dhat_xp_full * lik_d_full\n",
    "    p_dhat_xp_a = p_dhat_xp_a / np.sum(p_dhat_xp_a, axis=0, keepdims=True)\n",
    "    \n",
    "    # Conf = p(a=d)\n",
    "    if a == 1:\n",
    "        conf = p_dhat_xp_a[1, :]\n",
    "    else:\n",
    "        conf = p_dhat_xp_a[0, :]\n",
    "    \n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subj_idx</th>\n",
       "      <th>Stimulus</th>\n",
       "      <th>Response</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>RT_decision</th>\n",
       "      <th>RT_confidence</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6.848</td>\n",
       "      <td>2.217</td>\n",
       "      <td>VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.879</td>\n",
       "      <td>2.250</td>\n",
       "      <td>VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4.022</td>\n",
       "      <td>1.182</td>\n",
       "      <td>VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.106</td>\n",
       "      <td>1.803</td>\n",
       "      <td>VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611</td>\n",
       "      <td>1.254</td>\n",
       "      <td>VP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subj_idx  Stimulus  Response  Confidence  RT_decision  RT_confidence Task\n",
       "0         1         2         2           4        6.848          2.217   VP\n",
       "1         1         2         2           6        1.879          2.250   VP\n",
       "2         1         2         2           7        4.022          1.182   VP\n",
       "3         1         2         2           6        1.106          1.803   VP\n",
       "4         1         2         2           6        1.611          1.254   VP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_Mazancieux_2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized the variable\n",
    "# df_vp_std_f = np.std(df_vp['Confidence'],ddof=1)\n",
    "# df_vp_mean_f = np.mean(df_vp['Confidence'])\n",
    "# df_vp.loc[:, 'Confidence_standardized'] = (df_vp['Confidence'] - df_vp_mean_f) / df_vp_std_f\n",
    "\n",
    "# df_vp_std_r_f = np.std(df_vp['Response'],ddof=1)\n",
    "# df_vp_mean_r_f = np.mean(df_vp['Response'])\n",
    "# df_vp.loc[:, 'Response_standardized'] = (df_vp['Response'] - df_vp_mean_r_f) / df_vp_std_r_f\n",
    "\n",
    "# # check that it has mean 0 and sd 1\n",
    "# df_vp_std_conf = np.std(df_vp['Confidence_standardized'],ddof=1)\n",
    "# df_vp_mean_conf = np.mean(df_vp['Confidence_standardized'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### covarianza between confidence and response\n",
    "# Extraer las columnas 'Confidence' y 'Response'\n",
    "# confidence = df_vp['Confidence_standardized']\n",
    "# response = df_vp['Response_standardized']\n",
    "\n",
    "# # Calcular la covarianza usando np.cov\n",
    "# covariance_matrix = np.cov(confidence, response, ddof=1)\n",
    "# covariance = covariance_matrix[0, 1]\n",
    "\n",
    "# covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = df_vp.loc[:,'Stimulus_transformed'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to run the model, input: d (stimuli), output: confidence with and without serial dependence\n",
    "\n",
    "def model_run(d, a):\n",
    "\n",
    "    theta = [1/6, 2/6, 3/6, 4/6, 5/6] # [0/6, 1/6, 2/6, 3/6, 4/6, 5/6, 6/6] I delete two values because it was very easy o very difficult\n",
    "    sigmaAct = 1  # 1\n",
    "    sigmaConf = 1 # 1\n",
    "    rho = 0.5 # 0.5\n",
    "    bigSigma = np.array([[sigmaAct**2, rho * sigmaAct * sigmaConf], [rho * sigmaAct * sigmaConf, sigmaConf**2]])\n",
    "\n",
    "    # serial dependence weight. alpha = 3 and beta = 7 gives a E[p] of 0.3 given the ecuation alpha/(alpha+beta)\n",
    "    serial_dependence_weight_alpha = 3 \n",
    "    serial_dependence_weight_beta = 7\n",
    "\n",
    "    N = len(d) # 1000  # N trials\n",
    "\n",
    "    xa = np.empty(N)\n",
    "    xp = np.empty(N)\n",
    "    # xp_serialDependence = np.full( N, 111.0)\n",
    "    # d = df_vp.loc[:,'Stimulus_transformed'].values # np.empty(N)\n",
    "    # a = np.empty(N)\n",
    "    secondOrder_mean_cor = np.empty(N)\n",
    "    secondOrder_mean_cor_serialDependence =  np.full( N, 111.0)\n",
    "    # last_xp = np.empty(N)\n",
    "    first_trial = True\n",
    "\n",
    "    for i in range(N):\n",
    "        current_theta = random.choice(theta) \n",
    "        \n",
    "        # d[i] = 1 if np.random.rand() > 0.5 else -1\n",
    "        \n",
    "        r = multivariate_normal.rvs(mean=[d[i] * current_theta, d[i] * current_theta], cov=bigSigma)\n",
    "        \n",
    "        xa[i] = r[0]\n",
    "        xp[i] = r[1]\n",
    "        \n",
    "        # if xa[i] > 0:\n",
    "        #     a[i] = 1\n",
    "        #     flip_a = 1\n",
    "        # else:\n",
    "        #     a[i] = -1\n",
    "        #     flip_a = 0\n",
    "\n",
    "        flip_a = a[i]\n",
    "\n",
    "        secondOrder_mean_cor[i] = compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "        \n",
    "        if first_trial == False:\n",
    "            p_serial_dependence = np.random.beta(serial_dependence_weight_alpha, serial_dependence_weight_beta, 1)[0]\n",
    "            secondOrder_mean_cor_serialDependence[i] = (\n",
    "                p_serial_dependence * secondOrder_mean_cor_serialDependence[i-1] + \n",
    "                (1-p_serial_dependence) * compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "            )\n",
    "        else:\n",
    "            secondOrder_mean_cor_serialDependence[i] = compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "    \n",
    "        first_trial = False\n",
    "\n",
    "    # drop first value\n",
    "    secondOrder_mean_cor_adj = secondOrder_mean_cor[1:]\n",
    "    secondOrder_mean_cor_serialDependence_adj = secondOrder_mean_cor_serialDependence[1:]\n",
    "\n",
    "\n",
    "    return secondOrder_mean_cor_adj, secondOrder_mean_cor_serialDependence_adj\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model confidence to the Confidence without serial dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_17796\\3371121176.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx').apply(lambda x: x.iloc[1:]).reset_index(level=0, drop=True).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "## choose a task\n",
    "df_vp = df[df['Task'] == 'VP'].copy()\n",
    "\n",
    "## preproccess the stimulus\n",
    "df_vp.loc[:,'Stimulus_transformed'] = df_vp['Stimulus'].replace({1:-1,2:1})\n",
    "df_vp.loc[:,'Response_transformed'] = df_vp['Response'].replace({1:0,2:1})\n",
    "\n",
    "## initialize two list two save the results\n",
    "all_secondOrder_mean_cor = []\n",
    "all_secondOrder_mean_cor_serialDependence = []\n",
    "\n",
    "n_participants = len(df_vp['Subj_idx'].unique())\n",
    "\n",
    "for n_p in range(n_participants+1):\n",
    "    \n",
    "    df_vp_participant = df_vp[df_vp['Subj_idx'] == n_p] \n",
    "    d = df_vp_participant['Stimulus_transformed'].values\n",
    "    a = df_vp_participant['Response_transformed'].values\n",
    "    secondOrder_mean_cor, secondOrder_mean_cor_serialDependence = model_run(d,a)\n",
    "\n",
    "    # save results\n",
    "    all_secondOrder_mean_cor.extend(secondOrder_mean_cor)\n",
    "    all_secondOrder_mean_cor_serialDependence.extend(secondOrder_mean_cor_serialDependence)\n",
    "\n",
    "## drop the first row of each participant (the function model_run do the same)\n",
    "df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
    "\n",
    "## from list to array\n",
    "all_secondOrder_mean_cor = np.array(all_secondOrder_mean_cor)\n",
    "all_secondOrder_mean_cor_serialDependence = np.array(all_secondOrder_mean_cor_serialDependence)\n",
    "\n",
    "## from array to df\n",
    "df_results = pd.DataFrame({\n",
    "    'secondOrder_mean_cor': all_secondOrder_mean_cor,\n",
    "    'secondOrder_mean_cor_serialDependence': all_secondOrder_mean_cor_serialDependence\n",
    "})\n",
    "\n",
    "## concatenate results\n",
    "df_vp_final = pd.concat([df_vp_cleaned.reset_index(drop=True), df_results.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7059 entries, 0 to 7058\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Subj_idx                               7059 non-null   int64  \n",
      " 1   Stimulus                               7059 non-null   int64  \n",
      " 2   Response                               7059 non-null   int64  \n",
      " 3   Confidence                             7059 non-null   int64  \n",
      " 4   RT_decision                            7059 non-null   float64\n",
      " 5   RT_confidence                          7059 non-null   float64\n",
      " 6   Task                                   7059 non-null   object \n",
      " 7   Stimulus_transformed                   7059 non-null   int64  \n",
      " 8   Response_transformed                   7059 non-null   int64  \n",
      " 9   secondOrder_mean_cor                   7059 non-null   float64\n",
      " 10  secondOrder_mean_cor_serialDependence  7059 non-null   float64\n",
      " 11  Confidence_0to1                        7059 non-null   float64\n",
      "dtypes: float64(5), int64(6), object(1)\n",
      "memory usage: 661.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_vp_final['Confidence_0to1'] = df_vp_final['Confidence']/10\n",
    "df_vp_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model confidence to the Confidence with serial dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate several participants?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
