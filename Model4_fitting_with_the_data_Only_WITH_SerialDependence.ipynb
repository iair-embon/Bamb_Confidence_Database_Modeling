{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FLEMING'S FUNCTION MODIFIED\n",
    "def compute_meta_conf_serialdependence(xp, a, sigma_act, sigma_conf, rho):\n",
    "    \n",
    "    dhat = np.array([-1, 1])\n",
    "    mu_x_xp_dhat = np.zeros((2, len(xp)))\n",
    "    var_x_xp_dhat = np.zeros(len(xp))\n",
    "    rho_vec = np.full(len(xp), rho)\n",
    "    sigA_vec = np.full(len(xp), sigma_act)\n",
    "    sigP_vec = np.full(len(xp), sigma_conf)\n",
    "    \n",
    "    Tol = 10e-4\n",
    "\n",
    "    for dhati in range(2):\n",
    "        dhat_vec = np.full(len(xp), dhat[dhati])\n",
    "        \n",
    "        mu_x_xp_dhat[dhati, :] = dhat_vec + (sigA_vec / sigP_vec) * rho_vec * (xp - dhat_vec)\n",
    "        var_x_xp_dhat = (1 - rho_vec**2) * sigA_vec**2\n",
    "        \n",
    "        if a == 1:\n",
    "            p_a_dhat_xp = 1 - norm.cdf(0, mu_x_xp_dhat[dhati, :], np.sqrt(var_x_xp_dhat))\n",
    "        else:\n",
    "            p_a_dhat_xp = norm.cdf(0, mu_x_xp_dhat[dhati, :], np.sqrt(var_x_xp_dhat))\n",
    "        \n",
    "        lik_d = norm.pdf(xp, dhat_vec, sigP_vec)\n",
    "        \n",
    "        if dhati == 0:\n",
    "            p_a_dhat_xp_full = p_a_dhat_xp\n",
    "            lik_d_full = lik_d\n",
    "        else:\n",
    "            p_a_dhat_xp_full = np.vstack((p_a_dhat_xp_full, p_a_dhat_xp))\n",
    "            lik_d_full = np.vstack((lik_d_full, lik_d))\n",
    "    \n",
    "    # manage probability\n",
    "    p_a_dhat_xp_full = np.clip(p_a_dhat_xp_full, Tol, None)\n",
    "    lik_d_full = np.clip(lik_d_full, Tol, None)\n",
    "    \n",
    "    lik_d_full = lik_d_full / np.sum(lik_d_full, axis=0, keepdims=True)\n",
    "    p_dhat_xp_a = p_a_dhat_xp_full * lik_d_full\n",
    "    p_dhat_xp_a = p_dhat_xp_a / np.sum(p_dhat_xp_a, axis=0, keepdims=True)\n",
    "    \n",
    "    # Conf = p(a=d)\n",
    "    if a == 1:\n",
    "        conf = p_dhat_xp_a[1, :]\n",
    "    else:\n",
    "        conf = p_dhat_xp_a[0, :]\n",
    "    \n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "c:\\Users\\marcosembon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2071: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "c:\\Users\\marcosembon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2071: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "c:\\Users\\marcosembon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2071: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "c:\\Users\\marcosembon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2071: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
      "c:\\Users\\marcosembon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2071: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal rho: 0.2\n",
      "Optimal sigmaConf: 1.95\n",
      "Optimal theta: 0.15\n",
      "Optimal alpha sd: 7.0\n",
      "Optimal beta sd: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcosembon\\AppData\\Local\\Temp\\ipykernel_18844\\2516017357.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Función que devuelve una confianza con manipulación de dependencia serial y sin ella\n",
    "def model_run(d, a, rho, sigmaConf, theta, alpha_sd, beta_sd):\n",
    "    sigmaAct = 1\n",
    "    bigSigma = np.array([[sigmaAct**2, rho * sigmaAct * sigmaConf], [rho * sigmaAct * sigmaConf, sigmaConf**2]])\n",
    "\n",
    "    N = len(d)\n",
    "    xa = np.empty(N)\n",
    "    xp = np.empty(N)\n",
    "    secondOrder_mean_cor_serialDependence =  np.full( N, 111.0)\n",
    "    first_trial = True \n",
    "\n",
    "    for i in range(N):\n",
    "        current_theta = theta\n",
    "        r = multivariate_normal.rvs(mean=[d[i] * current_theta, d[i] * current_theta], cov=bigSigma)\n",
    "        \n",
    "        xa[i] = r[0]\n",
    "        xp[i] = r[1]\n",
    "        \n",
    "        flip_a = a[i]\n",
    "        \n",
    "        if first_trial == False:\n",
    "            p_serial_dependence = np.random.beta(alpha_sd, beta_sd, 1)[0]\n",
    "            secondOrder_mean_cor_serialDependence[i] = (\n",
    "                p_serial_dependence * secondOrder_mean_cor_serialDependence[i-1] + \n",
    "                (1-p_serial_dependence) * compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "            )\n",
    "        else:\n",
    "            secondOrder_mean_cor_serialDependence[i] = compute_meta_conf_serialdependence(np.array([xp[i]]), flip_a, sigmaAct, sigmaConf, rho)[0]\n",
    "    \n",
    "        first_trial = False\n",
    "\n",
    "    # drop first value\n",
    "    secondOrder_mean_cor_serialDependence_adj = secondOrder_mean_cor_serialDependence[1:]\n",
    "\n",
    "    return secondOrder_mean_cor_serialDependence_adj\n",
    "\n",
    "# Cargar datos y correr la optimización de los parámetros\n",
    "df = pd.read_csv('data_Mazancieux_2018.csv')\n",
    "df_vp = df[df['Task'] == 'VP'].copy()\n",
    "df_vp.loc[:, 'Stimulus_transformed'] = df_vp['Stimulus'].replace({1: -1, 2: 1})\n",
    "df_vp.loc[:, 'Response_transformed'] = df_vp['Response'].replace({1: 0, 2: 1})\n",
    "df_vp['Confidence_0to1'] = df_vp['Confidence'] / 10\n",
    "\n",
    "n_participants = len(df_vp['Subj_idx'].unique())\n",
    "\n",
    "def negative_log_likelihood(params):\n",
    "    rho = params[0]\n",
    "    sigmaConf = params[1]\n",
    "    theta = params[2]\n",
    "    alpha_sd = params[3]\n",
    "    beta_sd = params[4]\n",
    "\n",
    "    all_secondOrder_mean_cor_serialDependence = []\n",
    "\n",
    "    for n_p in range(n_participants+1):\n",
    "        df_vp_participant = df_vp[df_vp['Subj_idx'] == n_p]\n",
    "        d = df_vp_participant['Stimulus_transformed'].values\n",
    "        a = df_vp_participant['Response_transformed'].values\n",
    "        \n",
    "        secondOrder_mean_cor = model_run(d, a, rho, sigmaConf, theta, alpha_sd, beta_sd)\n",
    "\n",
    "        all_secondOrder_mean_cor_serialDependence.extend(secondOrder_mean_cor)\n",
    "\n",
    "    all_secondOrder_mean_cor_serialDependence = np.array(all_secondOrder_mean_cor_serialDependence)\n",
    "\n",
    "    df_vp_cleaned = df_vp.groupby('Subj_idx', group_keys=False).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n",
    "    conf_data = df_vp_cleaned['Confidence_0to1'].values\n",
    "   \n",
    "    log_likelihood = np.sum(norm.logpdf(conf_data, all_secondOrder_mean_cor_serialDependence))\n",
    "    \n",
    "    return -log_likelihood\n",
    "\n",
    "# Inicializar valores iniciales para los parámetros\n",
    "initial_guess = [0.5, 1.0, 0.5, 3, 7]  \n",
    "bounds = [(0, 1), (0.1, 2), (0.1, 0.9), (1,20),(1,20)]\n",
    "\n",
    "result = minimize(negative_log_likelihood, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "optimal_params = result.x\n",
    "optimal_rho = optimal_params[0]\n",
    "optimal_sigmaConf = optimal_params[1]\n",
    "optimal_theta = optimal_params[2]\n",
    "optimal_alpha_sd = optimal_params[3]\n",
    "optimal_beta_sd = optimal_params[4]\n",
    "\n",
    "print(\"Optimal rho:\", optimal_rho)\n",
    "print(\"Optimal sigmaConf:\", optimal_sigmaConf)\n",
    "print(\"Optimal theta:\", optimal_theta)\n",
    "print(\"Optimal alpha sd:\", optimal_alpha_sd)\n",
    "print(\"Optimal beta sd:\", optimal_beta_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOptimal rho: 0.4999999578896507\\nOptimal sigmaConf: 1.0000000347033007\\nOptimal theta: 0.49999994721446944\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Optimal rho: 0.5\n",
    "Optimal sigmaConf: 1.0\n",
    "Optimal theta: 0.5\n",
    "Optimal alpha sd: 3.0\n",
    "Optimal beta sd: 7.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Guardar en un archivo CSV\n",
    "with open('optimal_parameters_model_4_WITH_SerialDependence.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Parameter', 'Value'])\n",
    "    writer.writerow(['rho', optimal_rho])\n",
    "    writer.writerow(['sigmaConf', optimal_sigmaConf])\n",
    "    writer.writerow(['theta', optimal_theta])\n",
    "    writer.writerow(['alpha_sd', optimal_alpha_sd])\n",
    "    writer.writerow(['beta_sd', optimal_beta_sd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
